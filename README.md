# BlogCodes

MyWord2Vec.py 用全联接网络将“语料”训练,最后将对应的权重保存到相对路径下的“w.txt”文件下,还没有对保存后的权重矩阵做处理,主要是‘懒’.

MyTF-IDF.py 实现了初步的计算TF-IDF向量的功能,该方法基于统计和惩罚的机制对词汇的重要性进行划分,可以想象,当语料库较小的时候,这种词嵌入的方法会十分的糟糕!

Pytorch_RNN.py
使用了CharRNN对于语句序列进行学习, 通过将诗句划分成一个个字(没有采用分词的原因是对于不等长序列的处理还不够纯熟,有待改进.)
网络模型架构是一层Embedding层+GRU层+Relu层+输出层, 由于是采用的CharRNN所以, 每次输入RNN的batchsize都只能是1 , seq_length 就是一句话中包含的字数, 
除此之外, SGD的方法训练的所以网络的Loss波动很大
总结下来, 这个小实验对于自己了解RNN,LSTM,和GRU都还是挺有用的...至少明白了在pytorch框架下,RNN的需求输入和输出. 能比较好的转换了...
